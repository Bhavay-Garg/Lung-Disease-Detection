{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O49swHd8sGuj",
        "outputId": "c2e6f3bd-0315-4463-bdf8-856e315e611f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Lung-Disease-Detection'...\n",
            "remote: Enumerating objects: 10118, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10118 (delta 1), reused 10 (delta 1), pack-reused 10108\u001b[K\n",
            "Receiving objects: 100% (10118/10118), 2.17 GiB | 21.37 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (10101/10101), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Bhavay-Garg/Lung-Disease-Detection.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGPNXynnsJW1",
        "outputId": "5ff4f509-2301-45f8-f7e3-6abfed621fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x7fbef7b7ba90>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/Lung-Disease-Detection/Dataset'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFLRbo2scnY",
        "outputId": "335531e1-a89c-4e4a-c958-4dbf24663db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # for i in range(len(labels)):\n",
        "                #   labels[i]=labels[i]-1\n",
        "\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "R13iYJXqsoN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "NNZzwjeWssEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = torchvision.models.mobilenet_v3_large(pretrained=True, width_mult=1.0,  reduced_tail=False, dilated=False)\n",
        "# model_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7F6wxb2sup_",
        "outputId": "77f38676-c29d-498e-8458-b90f7914ce35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 88.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.classifier[0].in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_conv.classifier = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "QpD2Byk6s8XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcPHv6lttAhP",
        "outputId": "94362084-99f4-4dda-dc21-f1ac663a68ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.8170 Acc: 0.6924\n",
            "val Loss: 0.8204 Acc: 0.6478\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.6383 Acc: 0.7564\n",
            "val Loss: 0.8357 Acc: 0.6885\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.5858 Acc: 0.7734\n",
            "val Loss: 1.0173 Acc: 0.6295\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.5784 Acc: 0.7813\n",
            "val Loss: 0.9181 Acc: 0.6572\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.5599 Acc: 0.7872\n",
            "val Loss: 0.7977 Acc: 0.7029\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.5464 Acc: 0.7929\n",
            "val Loss: 0.7391 Acc: 0.7262\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.5279 Acc: 0.7991\n",
            "val Loss: 0.8877 Acc: 0.6865\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.4923 Acc: 0.8107\n",
            "val Loss: 0.8418 Acc: 0.6989\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.5071 Acc: 0.8054\n",
            "val Loss: 0.8431 Acc: 0.6989\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.4865 Acc: 0.8155\n",
            "val Loss: 0.8871 Acc: 0.6890\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.4775 Acc: 0.8186\n",
            "val Loss: 0.8619 Acc: 0.6925\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.4878 Acc: 0.8137\n",
            "val Loss: 0.8729 Acc: 0.6915\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.4804 Acc: 0.8163\n",
            "val Loss: 0.8351 Acc: 0.6989\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.5080 Acc: 0.8071\n",
            "val Loss: 0.7793 Acc: 0.7123\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.4733 Acc: 0.8254\n",
            "val Loss: 0.8679 Acc: 0.6895\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.4709 Acc: 0.8238\n",
            "val Loss: 0.8333 Acc: 0.7039\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.4897 Acc: 0.8167\n",
            "val Loss: 0.8382 Acc: 0.6954\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.4821 Acc: 0.8211\n",
            "val Loss: 0.8374 Acc: 0.6964\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.4833 Acc: 0.8180\n",
            "val Loss: 0.8281 Acc: 0.7059\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.4817 Acc: 0.8188\n",
            "val Loss: 0.8652 Acc: 0.6840\n",
            "\n",
            "Training complete in 51m 59s\n",
            "Best val Acc: 0.726190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_conv, '/content/MobileNet.pt')"
      ],
      "metadata": {
        "id": "zWavQr8Vzbbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3sEncPx297D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}